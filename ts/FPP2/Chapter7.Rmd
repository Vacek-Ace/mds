---
title: "Exercise solutions: Section 7.8"
author: "Rob J Hyndman and George Athanasopoulos"
output:
  html_document:
    fig_height: 5
    fig_width: 8
    toc: yes
    toc_depth: 1
    toc_float:
      collapsed: false
    number_sections: false
    theme: readable
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
library(fpp2)
options(digits=5)
```

# Ex 1
>Consider the `pigs` series --- the number of pigs slaughtered in Victoria each month.

>  a. Use the `ses` function in R to find the optimal values of $\alpha$ and $\ell_0$, and generate forecasts for the next four months.

```{r ex1a}
autoplot(pigs)
fcast.ses <- ses(pigs, h=4)
summary(fcast.ses)
```

>  b. Compute a 95\% prediction interval for the first forecast using $\hat{y} \pm 1.96s$ where $s$ is the standard deviation of the residuals. Compare your interval with the interval produced by R.

```{r ex1b, dependson='ex1a'}
sd.ses <- sqrt(var(residuals(fcast.ses)))
f1 <- head(fcast.ses[["mean"]],1)
c(Lower95 = f1 - 1.96 * sd.ses,
  Upper95 = f1 + 1.96 * sd.ses)
```

The intervals are close but not identical. This is because R estimates the variance of the residuals differently, taking account of the degrees of freedom properly.

```{r ex1c, dependson='ex1a'}
sd.ses <- sqrt(sum(residuals(fcast.ses)^2)/(length(pigs)-2))
c(Lower95 = f1 - 1.96 * sd.ses,
  Upper95 = f1 + 1.96 * sd.ses)
```

# Ex 2
>Write your own function to implement simple exponential smoothing. The function should take arguments `y` (the time series), `alpha` (the smoothing parameter $\alpha$) and `level` (the initial level $\ell_0$). It should return the forecast of the next observation in the series. Does it give the same forecast as `ses`?

```{r ex2}
myses <- function(y, alpha, level)
{
  n <- length(y)
  yhat <- numeric(n+1)
  yhat[1] <- level
  for(i in 2:(n+1)) {
    yhat[i] <- alpha * y[i-1] + (1 - alpha) * yhat[i-1]
  }
  return(tail(yhat,1))
}

c(my_forecast=myses(pigs, 0.2971, 77260.0561), 
  R_forecast=ses(pigs, h = 1)[["mean"]])
```

# Ex 3
>Modify your function from Q2 to return the sum of squared errors rather than the forecast of the next observation. Then use the `optim` function to find the optimal values of $\alpha$ and $\ell_0$. Do you get the same values as the `ses` function?

```{r}
myses.sse <- function(par, y)
{
  alpha <- par[1]
  level <- par[2]
  n <- length(y)
  yhat <- numeric(n)
  yhat[1] <- level
  for(i in 2:n) {
    yhat[i] <- alpha * y[i-1] + (1 - alpha) * yhat[i-1]
  }
  return(sum((y - yhat)^2))
}

options(digits=8)
optim(c(0.1, pigs[1]), myses.sse, y=pigs)$par
fcast.ses$model$par
```
```{r echo=FALSE}
options(digits=5)
```

Similar, but not identical estimates. This is due to different starting values being used.

# Ex 4

```{r ex4}
myses.sse <- function(par, y)
{
  alpha <- par[1]
  level <- par[2]
  n <- length(y)
  yhat <- numeric(n)
  yhat[1] <- level
  for(i in 2:n) {
    yhat[i] <- alpha * y[i-1] + (1 - alpha) * yhat[i-1]
  }
  return(sum((y - yhat)^2))
}
myses <- function(y, h=10)
{
  par <- optim(c(0.1, y[1]), myses.sse, y=y)$par
  alpha <- par[1]
  level <- par[2]
  n <- length(y)
  yhat <- numeric(n+1)
  yhat[1] <- level
  for(i in 2:(n+1)) {
    yhat[i] <- alpha * y[i-1] + (1 - alpha) * yhat[i-1]
  }
  return(rep(yhat[n+1], h))
}
# Usage:
myses(pigs)
# Compare:
ses(pigs)
```

# Ex 5

>Data set `books` contains the daily sales of paperback and hardcover books at the same store. The task is to forecast the next four days’ sales for paperback and hardcover books.

>    a. Plot the series and discuss the main features of the data.

```{r}
autoplot(books)
```

Both series are trended, with a similar slope. There is no obvious weekly seasonality.

>    b. Use the `ses` function to forecast each series, and plot the forecasts.

```{r}
fcast1 <- ses(books[,"Hardcover"], h=4)
fcast2 <- ses(books[,"Paperback"], h=4)
autoplot(books) +
  autolayer(fcast1, series="Hardcover", PI=FALSE) +
  autolayer(fcast2, series="Paperback", PI=FALSE)
```

>    c. Compute the RMSE values for the training data in each case.

```{r}
accuracy(fcast1)
accuracy(fcast2)
```

# Ex 6

>    a. Now apply Holt’s linear method to the `paperback` and `hardback` series and compute four-day forecasts in each case.

```{r}
fcast1 <- holt(books[,"Hardcover"], h=4)
fcast2 <- holt(books[,"Paperback"], h=4)
autoplot(books) +
  autolayer(fcast1, series="Hardcover", PI=FALSE) +
  autolayer(fcast2, series="Paperback", PI=FALSE)
```

>    b. Compare the RMSE measures of Holt’s method for the two series to those of simple exponential smoothing in the previous question. (Remember that Holt’s method is using one more parameter than SES.) Discuss the merits of the two forecasting methods for these data sets.

```{r}
accuracy(fcast1)
accuracy(fcast2)
```

There's been a big redution in RMSE, even allowing for the extra parameter. That's not surprising as these series are clearly trended.


>    c. Compare the forecasts for the two series using both methods. Which do you think is best?

The results from `holt` are all higher than those from `ses` because it allows for the increasing trend.

Holt's method is to be preferred here.

>    d. Calculate a 95% prediction interval for the first forecast for each series, using the RMSE values and assuming normal errors. Compare your intervals with those produced using `ses` and `holt`.

```{r}
s <- sqrt(fcast1$model$mse)
High <- fcast1$mean[1] + 1.96*s
Low <- fcast1$mean[1] - 1.96*s
fcast1
c(Low = Low, High = High)

s <- sqrt(fcast2$model$mse)
High <- fcast2$mean[1] + 1.96*s
Low <- fcast2$mean[1] - 1.96*s
fcast2
c(Low = Low, High = High)
```

As with Exercise 1b, `holt()` is estimating the standard deviation of the results using a method that takes account of the degrees of freedom. So the results are slightly different.

# Ex 7

>For this exercise, use data set `eggs`, the price of a dozen eggs in the United States from 1900--1993. Experiment with the various options in the `holt()` function to see how much the forecasts change with damped trend, or  with a Box-Cox transformation. Try to develop an intuition of what each argument is doing to the forecasts.
>
>[Hint: use `h=100` when calling `holt()` so you can clearly see the differences between the various options when plotting the forecasts.]
>
>Which model gives the best RMSE?


```{r}
# Best model:
fc <- holt(eggs, h=100, lambda=0.17, damped=FALSE)
accuracy(fc)
```

# Ex 8
> Recall your retail time series data  (from Exercise 3 in Section 2.10).

>  a. Why is multiplicative seasonality necessary for this series?

```{r ex8a}
myts <- readxl::read_excel("data/retail.xlsx", skip=1)[,"A3349873A"] %>%
  ts(frequency=12, start=c(1982,4))
autoplot(myts)
```

The seasonal variation increases with the level of the series. So we need to use multiplicative seasonality.

>  b. Apply Holt-Winters’ multiplicative method to the data. Experiment with making the trend damped.

```{r ex8b}
fc1 <- hw(myts, seasonal='multiplicative', damped=FALSE)
autoplot(fc1)
fc2 <- hw(myts, seasonal='multiplicative', damped=TRUE)
autoplot(fc2)
```  

>  c. Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?

```{r ex8c} 
accuracy(fc1)
accuracy(fc2)
```

There is not much difference between these models, but the non-damped one has slightly better training RMSE. Also, we would expect the trend to continue, so I would prefer to use the non-damped version.

>  d. Check that the residuals from the best method look like white noise.

```{r ex8d}
checkresiduals(fc1)
```

There are significant correlations in the residuals, including at lags 1 and 2. So these residuals do not look like white noise.

>  e. Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naïve approach from Exercise 8 in Section 3.7)?

```{r ex8e}
myts %>% window(end=c(2010,12)) %>%
  hw(seasonal='multiplicative', damped=FALSE) %>%
  accuracy(x=myts)
```

The test set RMSE is 70.117 compared to 71.443 for the seasonal naïve method. So not a big difference, but Holt-Winters' method is slightly better.


# Ex 9
> For the same retail data, try an STL decomposition applied to the Box-Cox transformed series, followed by ETS on the seasonally adjusted data. How does that compare with your best previous forecasts on the test set?

```{r ex9, dependson='ex8a'}
myts %>% window(end=c(2010,12)) %>%
  stlf(lambda=0) %>%
  accuracy(x=myts)
``` 

That is worse (73.704 compared to 70.117).

# Ex 10
>For this exercise, use the quarterly UK passenger vehicle production data from 1977Q1--2005Q1 (data set `ukcars`).

>a. Plot the data and describe the main features of the series.

```{r}
autoplot(ukcars) + ylab("Production, thousands of cars")
```

* The data are seasonal with a nonlinear trend.

>b. Decompose the series using STL and obtain the seasonally adjusted data.

```{r}
stlFit <- stl(ukcars, s.window = "periodic")
autoplot(stlFit)
adjusted <- seasadj(stlFit)
autoplot(adjusted)
```

>c. Forecast the next two years of the series using an additive damped trend method applied to the seasonally adjusted data. (This can be done in one step using `stlf` with arguments `etsmodel="AAN", damped=TRUE`.)

```{r, comment=""}
fcastHoltDamp <- stlf(ukcars, etsmodel="AAN", damped=TRUE)
autoplot(ukcars) +
  autolayer(fcastHoltDamp, PI=FALSE)
```

>d. Forecast the next two years of the series using Holt’s linear method applied to the seasonally adjusted data (as before but with `damped=FALSE`).

```{r}
fcastHolt <- stlf(ukcars, etsmodel="AAN", damped=FALSE)
autoplot(ukcars) +
  autolayer(fcastHolt, PI=FALSE)
```

>e. Now use `ets()` to choose a seasonal model for the data.

```{r}
ukcarsets <- ets(ukcars)
```

>f. Compare the RMSE of the ETS model with the RMSE of the models you obtained using  STL decompositions.  Which gives the better in-sample fits?

```{r}
accuracy(fcastHoltDamp)
accuracy(fcastHolt)
accuracy(ukcarsets)
```

Holt's method does slightly better in-sample.

>g. Compare the forecasts from the three approaches? Which seems most reasonable?

```{r}
autoplot(ukcars) +
  autolayer(fcastHoltDamp, PI=FALSE, series="Damped Holt's") +
  autolayer(fcastHolt, PI=FALSE, series="Holt's") +
  autolayer(forecast(ukcarsets), PI=FALSE, series="ETS")
```

The forecasts are almost identical. So I'll use the Holt's method which has smallest RMSE.

>h. Check the residuals of your preferred model.

```{r}
checkresiduals(fcastHolt)
```

There is some significant autocorrelation at lags 4, 8, 11, 12 and 18. The ETS model is slightly better, although still significant.

```{r}
checkresiduals(ukcarsets)
```

I'd probably go with the ETS model here due to its slightly better residual properties.


# Ex 11
>For this exercise, use the monthly Australian short-term overseas visitors data, May 1985--April 2005. (Data set: `visitors`.)
>
>  a. Make a time plot of your data and describe the main features of the series.

```{r}
autoplot(visitors) + ylab("Thousands of people")
```

* The data has upward trend.
* The data has seasonal pattern which increases in size approximately proportionally to the average number of people who arrive per year. Therefore, the data has multiplicative seasonality.

>  b. Split your data into a training set and a test set comprising the last two years of available data. Forecast the test set using Holt-Winters’ multiplicative method.

```{r, comment=""}
train <- window(visitors, end=end(visitors)-c(2,0))
fcast <- hw(train, h=24, seasonal="multiplicative")
autoplot(fcast) +
  autolayer(visitors)
```

>c. Why is multiplicative seasonality necessary here?

The multiplicative seasonality is important in this example because seasonal pattern increases in size proportionally to the level of the trend.

>d. Forecast the two-year test set using each of the following methods:
>     i) an ETS model;
>     ii) an additive ETS model applied to a Box-Cox transformed series;
>     iii) a seasonal naïve method;
>     iv) an STL decomposition applied to the Box-Cox transformed data followed by an ETS model applied to the seasonally adjusted (transformed) data.

```{r}
f1 <- forecast(ets(train))
f2 <- forecast(ets(train, lambda=0))
f3 <- snaive(train)
f4 <- stlf(train, lambda=0)
autoplot(visitors) +
  autolayer(f1, PI=FALSE, series="ETS") +
  autolayer(f2, PI=FALSE, series="Additive ETS with Box-Cox") +
  autolayer(f3, PI=FALSE, series="Seasonal naïve") +
  autolayer(f4, PI=FALSE, series="STL+ETS with Box-Cox")
```

> e. Which method gives the best forecasts? Does it pass the residual tests?

```{r}
accuracy(f1,visitors)
accuracy(f2,visitors)
accuracy(f3,visitors)
accuracy(f4,visitors)
```

The best method is seasonal naïve, although it fails the residuals tests:

```{r}
checkresiduals(f3)
```

> f. Compare the same four methods using time series cross-validation with the `tsCV` function instead of using a training and test set. Do you come to the same conclusions?

```{r}
e <- matrix(NA,ncol=4,nrow=length(visitors))
f1 <- function(y,h){forecast(ets(y),h=h)}
e[,1] <- tsCV(visitors, f1)
f2 <- function(y,h){forecast(ets(y, lambda=0),h=h)}
e[,2] <- tsCV(visitors, f2)
e[,3] <- tsCV(visitors, snaive)
e[,4] <- tsCV(visitors, stlf, lambda=0)
colMeans(e^2, na.rm=TRUE)
```

Now the STLF method appears better (based on 1-step forecasts), even though it was worst on the test set earlier.

# Ex 12

The `fets()` function below returns ETS forecasts.

```{r}
fets <- function(y, h) {
  forecast(ets(y), h = h)
}
```

a. Apply `tsCV()` for a forecast horizon of $h=4$, for both ETS and seasonal naïve methods to the `qcement` data, (Hint: use the newly created `fets()` and the existing `snaive()` functions as your forecast function arguments.)

```{r}
e1 <- tsCV(qcement, fets, h=4)
e2 <- tsCV(qcement, snaive, h=4)
```

b. Compute the MSE of the resulting 4-step-ahead errors. (Hint: make sure you remove missing values.) Why are there missing values? Comment on which forecasts are more accurate. Is this what you expected?

```{r}
colMeans(e1^2, na.rm=TRUE)
colMeans(e2^2, na.rm=TRUE)
```

The ETS results are much better for the first 3 horizons, but the `snaive` results are slightly better for $h=4$. With a long series like this, I would expect ETS to do better as it should have no trouble estimating the parameters, and it will include trends if required. 

# Ex 13
>Compare `ets`, `snaive` and `stlf` on the following six time series. For `stlf`, you might need to use a Box-Cox transformation. Use a test set of three years to decide what gives the best forecasts.
       `ausbeer`, `bricksq`, `dole`, `a10`, `h02`, `usmelec`.

```{r}
autoplot(ausbeer)
```

A Box-Cox transformation does not seem to be required for this series.

```{r}
train <- window(ausbeer, end=end(ausbeer)-c(3,0))
fc1 <- forecast(ets(train))
fc2 <- snaive(train)
fc3 <- stlf(train)
accuracy(fc1, ausbeer)
accuracy(fc2, ausbeer)
accuracy(fc3, ausbeer)
```

Here, `ets` does best (based on RMSE) over the three year training set.

The other series are handled similarly.

# Ex 14
>a. Use `ets()` on some of these series:
>        `bicoal`, `chicken`, `dole`, `usdeaths`, `lynx`, `ibmclose`, `eggs`.
>
>      Does it always give good forecasts?


```{r}
bicoal %>% ets %>% forecast %>% autoplot
chicken %>% ets(lambda=0) %>% forecast %>% autoplot
```

I've used a log transformation here to prevent the forecast intervals going negative

```{r}
dole %>% ets(lambda=0) %>% forecast %>% autoplot
```

Again, a Box-Cox transformation is necessary. The point forecasts look too low, and the forecast intervals are far too wide. It might be necessary to only model the last few years of the data.

```{r}
dole %>% window(start=1975) %>% ets %>% forecast %>% autoplot
```

That looks a little more reasonable, although now the intervals are probably too narrow.

```{r}
usdeaths %>% ets %>% forecast %>% autoplot
lynx %>% ets %>% forecast %>% autoplot
```

Here the cyclic behaviour of the lynx data is completely lost. ETS models are not designed to handle cyclic data, so there is nothing that can be done to improve this.

```{r}
ibmclose %>% ets %>% forecast %>% autoplot
eggs %>% ets %>% forecast %>% autoplot
```

>b. Find an example where it does not work well. Can you figure out why?

See comments on lynx above.

# Ex 15
>Show that the point forecasts from an ETS(M,A,M) model are the same as those obtained using multiplicative Holt-Winters' method.


Point forecasts from the multiplicative Holt-Winters' method:
$$
  \hat{y}_{t+h|t} = (\ell_t + hb_t)s_{t-m+h_m^+}
$$

An ETS(M,A,M) model is given by
\begin{align*}
  y_t    & = (\ell_{t-1}+b_{t-1})s_{t-m}(1+\varepsilon_t) \\
  \ell_t & = (\ell_{t-1}+b_{t-1})(1+\alpha\varepsilon_t) \\
  b_t    & = b_{t-1} + \beta(\ell_{t-1}+b_{t-1})\varepsilon_t \\
  s_t    & = s_{t-m} (1+\gamma\varepsilon_t)
\end{align*}
So $y_{T+h}$ is given by
$$
  y_{T+h} = (\ell_{T+h-1}+b_{T+h-1})s_{T+h-m}(1+\varepsilon_{T+h-m})
$$
Replacing $\varepsilon_{t}$ by zero for $t>T$, and substituting in from the above equations, we obtain
$$
  \hat{y}_{T+h} = (\ell_{T+h-2}+2b_{T+h-2})s_{T+h-m}
$$
Repeating the process a few times leads to
$$
  \hat{y}_{T+h} = (\ell_{T}+hb_{T})s_{T+h-m}
$$
Doing the same thing for $s_{T+h-m}$ gives
$$
  \hat{y}_{T+h|T} = (\ell_{T}+hb_{T})s_{T+h_m^+-m}
$$
as required.



# Ex 16
>Show that the forecast variance for an ETS(A,N,N) model is given by
$$
\sigma^2\left[1+\alpha^2(h-1)\right].
$$

An ETS(A,N,N) model is defined as
  \begin{align*}
    y_t      & = \ell_{t-1} + \varepsilon_{t} \\
    \ell_{t} & = \ell_{t-1} + \alpha\varepsilon_{t},
  \end{align*}
where $\varepsilon_t \sim \text{N}(0,\sigma^2)$, and $h$-step forecasts are  given by
$$
 \hat{y}_{T+h|T} = \ell_T.
$$
So
  \begin{align*}
     y_{T+h} & = \ell_{T+h-1} + \varepsilon_{T+h} \\
             & = \ell_{T+h-2} + \alpha \varepsilon_{T+h-1} +  \varepsilon_{T+h} \\
             & = \ell_{T+h-3} + \alpha \varepsilon_{T+h-2}  + \alpha \varepsilon_{T+h-1} +  \varepsilon_{T+h} \\
             & \dots \\
             & = \ell_{T} + \alpha \sum_{j=1}^{h-1} \varepsilon_{T+h-j} +  \varepsilon_{T+h}.
  \end{align*}
Therefore
  \begin{align*}
    \text{Var}(y_{T+h} | y_1,\dots,y_T) & = \alpha^2 \sum_{j=1}^{h-1} \sigma^2 +  \sigma^2 \\
                                        & =  \sigma^2\left[ 1 + \alpha^2 (h-1)\right ].
  \end{align*}

# Ex 17
>Write down the 95\% prediction intervals for an ETS(A,N,N) model as a function of $\ell_T$, $\alpha$, $h$ and $\sigma$, assuming Gaussian errors.

Using previous result:
$$
 \ell_T \pm 1.96 \sigma \sqrt{ 1 + \alpha^2 (h-1)}
$$

