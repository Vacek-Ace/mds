{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-multiflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-multiflow` es un paquete de aprendizaje automático de código abierto para la transmisión de datos. Amplía las herramientas científicas disponibles en el ecosistema de Python. scikit-multiflow está pensado para aplicaciones de flujo de datos en las que los datos se generan continuamente y deben ser procesados y analizados sobre la marcha. Las muestras de datos no se almacenan, por lo que los métodos de aprendizaje están expuestos a nuevos datos sólo una vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-multiflow` está disponible a través PyPI. Así que puedes instalarlo usando el siguiente comando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! pip install -U scikit-multiflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente imagen ilustra los múltiples métodos implementados en scikit-multiflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scikit-multiflow_map.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Imports\n",
    "from skmultiflow.data import FileStream\n",
    "from skmultiflow.data import SEAGenerator\n",
    "from skmultiflow.evaluation import EvaluatePrequential\n",
    "from skmultiflow.bayes import NaiveBayes\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "from skmultiflow.trees import HoeffdingAdaptiveTreeClassifier\n",
    "from skmultiflow.drift_detection import ADWIN\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, mostramos cómo configurar y ejecutar fácilmente experimentos en `scikit-multiflow`.\n",
    "\n",
    "La demostración se divide en las siguientes partes:\n",
    "\n",
    "1. Ejecución de una tarea de clasificación  \n",
    "  1. Implementación de la evaluación previa\n",
    "  2. La clase `EvaluatePrequential`\n",
    "\n",
    "2. Detección de la deriva conceptual\n",
    "  1. Prueba de detección de deriva\n",
    "  2. Impacto en el rendimiento predictivo\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Ejecutar una tarea de clasificación\n",
    "\n",
    "En este caso utilizaremos el generador de flujos `SEA`. Un generador de datos no almacena ningún dato, sino que lo genera bajo demanda.\n",
    "\n",
    "A continuación configuraremos un método de aprendizaje (modelo, estimador, algoritmo), en este caso el clasificador Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "stream = SEAGenerator(random_state=1)\n",
    "classifier = NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación previa\n",
    "\n",
    "La evaluación previa se implementa fácilmente como un bucle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 samples analyzed.\n",
      "NaiveBayes classifier accuracy: 0.9395\n"
     ]
    }
   ],
   "source": [
    "# Variables to control evaluation loop and track performance\n",
    "n_samples = 0\n",
    "correct_cnt = 0\n",
    "max_samples = 2000\n",
    "\n",
    "# Prequential evaluation loop\n",
    "while n_samples < max_samples and stream.has_more_samples():\n",
    "   X, y = stream.next_sample()      # Get one sample from the stream\n",
    "   y_pred = classifier.predict(X)   # Predict class for new data\n",
    "   if y[0] == y_pred[0]:\n",
    "       correct_cnt += 1\n",
    "   classifier.partial_fit(X, y)     # Incrementally train the model with the new data\n",
    "   n_samples += 1\n",
    "\n",
    "print('{} samples analyzed.'.format(n_samples))   \n",
    "print('NaiveBayes classifier accuracy: {}'.format(correct_cnt / n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase `EvaluatePrequential`\n",
    "\n",
    "Implementa el método de evaluación prequencial y proporciona funcionalidades extra.\n",
    "\n",
    "Hagamos el mismo experimento con los datos de la EAE pero esta vez compararemos dos clasificadores:\n",
    "\n",
    "1. `NaiveBayes`.\n",
    "2. `SGDClassifier`: SVM lineal con entrenamiento SGD.\n",
    "\n",
    "Elegimos el `SGDClassifier` para demostrar la compatibilidad con los métodos incrementales de `scikit-learn`.\n",
    "\n",
    "**Nota: `scikit-learn` se centra en el aprendizaje por lotes y sólo un número **limitado** de sus métodos son capaces de aprender de forma incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Setup stream and estimators\n",
    "stream = SEAGenerator(random_state=1)\n",
    "nb = NaiveBayes()\n",
    "svm = SGDClassifier()\n",
    "\n",
    "# Setup evaluator\n",
    "eval = EvaluatePrequential(show_plot=True,\n",
    "                           max_samples=20000,\n",
    "                           metrics=['accuracy', 'kappa', 'running_time', 'model_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0a214268044e89a1410bb5d7ed4274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prequential Evaluation\n",
      "Evaluating 1 target(s).\n",
      "Pre-training on 200 sample(s).\n",
      "Evaluating...\n",
      " #################### [100%] [9.59s]\n",
      "Processed samples: 20000\n",
      "Mean performance:\n",
      "NB - Accuracy     : 0.9430\n",
      "NB - Kappa        : 0.8621\n",
      "NB - Training time (s)  : 0.54\n",
      "NB - Testing time  (s)  : 1.41\n",
      "NB - Total time    (s)  : 1.96\n",
      "NB - Size (kB)          : 6.8076\n",
      "SVM - Accuracy     : 0.9559\n",
      "SVM - Kappa        : 0.8982\n",
      "SVM - Training time (s)  : 4.56\n",
      "SVM - Testing time  (s)  : 1.80\n",
      "SVM - Total time    (s)  : 6.36\n",
      "SVM - Size (kB)          : 3.4453\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "eval.evaluate(stream=stream, model=[nb, svm], model_names=['NB', 'SVM']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Deriva conceptual\n",
    "\n",
    "#### Simular un flujo de datos con deriva conceptual\n",
    "\n",
    "Para este caso, generaremos un flujo de datos sintético concatenando 3 distribuciones de 1000 muestras cada una:\n",
    "- $dist_a$: $\\mu=0,8$, $\\sigma=0,05$\n",
    "- $dist_b$: $\\mu=0,4$, $\\sigma=0,02$\n",
    "- $dist_c$: $\\mu=0,6$, $\\sigma=0,1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2451a08cbe34cb0964f8931d4f2b8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_state = np.random.RandomState(12345)\n",
    "dist_a = random_state.normal(0.8, 0.05, 1000)\n",
    "dist_b = random_state.normal(0.4, 0.02, 1000)\n",
    "dist_c = random_state.normal(0.6, 0.1, 1000)\n",
    "\n",
    "stream = np.concatenate((dist_a, dist_b, dist_c))\n",
    "\n",
    "# Plot the data\n",
    "fig = plt.figure(figsize=(7,3), tight_layout=True)\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n",
    "ax1, ax2 = plt.subplot(gs[0]), plt.subplot(gs[1])\n",
    "ax1.grid()\n",
    "ax1.plot(stream, label='Stream')\n",
    "ax2.grid(axis='y')\n",
    "ax2.hist(dist_a, label=r'$dist_a$')\n",
    "ax2.hist(dist_b, label=r'$dist_b$')\n",
    "ax2.hist(dist_c, label=r'$dist_c$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de detección de deriva\n",
    "\n",
    "En este ejemplo utilizaremos el método de detección de deriva ADaptive WINdowing (`ADWIN`).\n",
    "\n",
    "El objetivo es detectar que se ha producido una deriva, después de las muestras **1000** y **2000** en el flujo de datos sintéticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change detected at index 1055\n",
      "Change detected at index 2079\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the ADWIN drift detector\n",
    "drift_detector = ADWIN()\n",
    "\n",
    "for i, val in enumerate(stream):\n",
    "    drift_detector.add_element(val)        # Data is processed one sample at a time\n",
    "    if drift_detector.detected_change():\n",
    "        print('Change detected at index {}'.format(i))\n",
    "        drift_detector.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impacto en el rendimiento predictivo\n",
    "\n",
    "En este caso utilizaremos dos modelos de adaptativos populares:\n",
    "\n",
    "1. El `Hoeffding Tree` es un tipo de árbol de decisión diseñado para flujos de datos.\n",
    "2. El `Hoeffding Adaptive Tree` es una mejora del `Hoeffding Tree` original.\n",
    "\n",
    "El `Hoeffding Adaptive Tree` utiliza `ADWIN` para detectar cambios, si se detecta un cambio en una rama determinada, se crea una rama alternativa y acaba sustituyendo la rama original si muestra un mejor rendimiento con los nuevos datos.\n",
    "\n",
    "Para este ejemplo cargaremos los datos desde un archivo csv utilizando la clase `FileStream`.\n",
    "\n",
    "Los datos corresponden a la salida del `AGRAWALGenerator` con 3 **derivas graduales** en las marcas de 5k, 10k y 15k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "stream = FileStream(\"agr_a_20k.csv\")\n",
    "# Setup estimators\n",
    "cfiers = [HoeffdingTreeClassifier(), HoeffdingAdaptiveTreeClassifier()]\n",
    "# Setup evaluations\n",
    "eval = EvaluatePrequential(show_plot=True,\n",
    "                           metrics=['accuracy', 'kappa', 'model_size'],\n",
    "                           n_wait=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e502a26b1f214c9596f1372d374538a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prequential Evaluation\n",
      "Evaluating 1 target(s).\n",
      "Pre-training on 200 sample(s).\n",
      "Evaluating...\n",
      " #################### [100%] [14.76s]\n",
      "Processed samples: 20000\n",
      "Mean performance:\n",
      "HT - Accuracy     : 0.7279\n",
      "HT - Kappa        : 0.4530\n",
      "HT - Size (kB)          : 175.8711\n",
      "HAT - Accuracy     : 0.7612\n",
      "HAT - Kappa        : 0.5197\n",
      "HAT - Size (kB)          : 91.9268\n"
     ]
    }
   ],
   "source": [
    "eval.evaluate(stream=stream, model=cfiers, model_names=['HT', 'HAT']);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mds] *",
   "language": "python",
   "name": "conda-env-mds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
